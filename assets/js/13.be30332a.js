(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{398:function(t,_,a){t.exports=a.p+"assets/img/4.0e217fb7.png"},399:function(t,_,a){t.exports=a.p+"assets/img/image-20220314200800658.9753a227.png"},400:function(t,_,a){t.exports=a.p+"assets/img/2.f8304523.png"},401:function(t,_,a){t.exports=a.p+"assets/img/image-20220314191449603.1177d2b3.png"},402:function(t,_,a){t.exports=a.p+"assets/img/3.8337df43.png"},560:function(t,_,a){"use strict";a.r(_);var e=a(56),v=Object(e.a)({},(function(){var t=this,_=t.$createElement,e=t._self._c||_;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"论文阅读-nocs-normalized-object-coordinate-space-of-category-level-6d-object-pose-and-size-estimation"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#论文阅读-nocs-normalized-object-coordinate-space-of-category-level-6d-object-pose-and-size-estimation"}},[t._v("#")]),t._v(" [论文阅读]NOCS:Normalized object coordinate space of category level 6D object pose and size estimation")]),t._v(" "),e("h2",{attrs:{id:"在前面"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#在前面"}},[t._v("#")]),t._v(" 在前面")]),t._v(" "),e("p",[t._v("这篇文章是CVPR 2019 oral，最关键就是提出了NOCS这个概念以及NOCS数据集，目前看到的类级别相关的检测和跟踪工作都是在这个数据集上跑的。因此了解NOCS的概念以及了解NOCS数据集的结构都是很重要的。")]),t._v(" "),e("p",[t._v("顺带一提，NOCS的数据集结构基本找不到什么说明，刚下载看的时候一头雾水。还好作者的两篇文章NOCS和CAPTRA公布了源码，对照源码里面的数据集处理能看个差不多。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(398),alt:"4"}}),t._v("数据集大致结构")]),t._v(" "),e("p",[t._v("放点自己的跑的结果：")]),t._v(" "),e("p",[e("img",{attrs:{src:a(399),alt:"image-20220314200800658"}})]),t._v(" "),e("h2",{attrs:{id:"论文概要"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#论文概要"}},[t._v("#")]),t._v(" 论文概要")]),t._v(" "),e("p",[e("strong",[t._v("目标")]),t._v("：估计类级别(category level)对象的6D位姿和尺寸，类级别与实例级别(instance level)相对，类级别在训练和测试时没有对象的精确CAD模型")]),t._v(" "),e("p",[t._v("为了处理同一类别中不同的或者未见过的实例，引入归一化物体坐标空间(NOCS,Normalized Object Coordinated Space)对一个类中所有可能实例的共享规范化表示")]),t._v(" "),e("p",[t._v("使用基于区域的(region-based)神经网络,训练网络用来直接推断观察像素与NOCS以及其他信息（如类标签，instance mask）的对应关系。预测的结果能够结合深度图来联合估计杂乱场景中多个物体6D位姿和尺寸(dimension)")]),t._v(" "),e("p",[t._v("为了训练网络，提出了一种新的上下文感知技术来生成大量的标注混合现实数据。为了进一步改善模型并评估其在真实数据中的性能，也提供了真实数据集")]),t._v(" "),e("p",[t._v("现有的6D姿态估计方法")]),t._v(" "),e("p",[t._v("1.实例级别的6D姿态估计需要预知物体的精确的CAD模型和尺寸(size)")]),t._v(" "),e("p",[t._v("2.类级别的3D物体检测方法可以估计物体的类别标签和3D边界框，无需精确CAD模型，但是估计出的bbox依赖于视点(viewpoint-dependent)，并且没有物体的朝向(orientation)")]),t._v(" "),e("p",[e("strong",[t._v("第一个问题是由于没有"),e("strong",[e("strong",[t._v("CAD")])]),t._v("模型，需要找到一种表示方式，能够定义同一类别不同物体"),e("strong",[e("strong",[t._v("6")])]),t._v("位姿和尺寸")])]),t._v(" "),e("p",[e("strong",[t._v("第二个问题是在训练和测试时没有可用的大规模数据集")])]),t._v(" "),e("p",[e("strong",[t._v("如何表示位姿？")]),t._v("，将本文问题换个说法：找到物体像素和归一化坐标空间中的对应关系")]),t._v(" "),e("p",[t._v("定义归一化物体坐标空间NOCS，其中所有的对象都包含在一个公共规范化空间中，并且同一类别中所有实例物体的朝向都是一致的，这样就·能够6D位姿和尺寸的估计。")]),t._v(" "),e("p",[t._v("方法的核心是一个CNN，从单张RGB图像估计图像中多物体的类别、实例mask和NOCS map")]),t._v(" "),e("p",[t._v("直观地，NOCS map 通过预测物体像素和NOCS之间的密集对应（dense correspondence）来捕获物体的可见部分的标准化形状。CNN通过将其描述为像素回归或分类问题来估计NOCS图，然后使用位姿拟合，将NOCS图和深度图用来估计完整的6D位姿和尺寸。方法使用RGB-D输入，能够处理对称和非对称物体")]),t._v(" "),e("p",[e("strong",[t._v("为了解决训练数据问题")]),t._v("，使用了一种混合现实方法，能够自动生成大量数据，这些数据是由ShapeNet中“逼真”（完全不）的合成图像和真实的桌面场景合成的。")]),t._v(" "),e("p",[t._v("该方法能生成具有多个对象的真实数据，以及类标签、实例mask、NOCS map、6D位姿、尺寸以及完整的ground truth注释。")]),t._v(" "),e("p",[t._v("除了合成数据集，还提供了一个真实世界的数据集，包含18个不同场景，6种物体类别，42个不同的实例。")]),t._v(" "),e("p",[t._v("现有的类级别位姿估计都局限于4DOF(例如汽车的位姿估计就是最常见的，因为车的形状都差不多)")]),t._v(" "),e("p",[t._v("1.首先这些算法都约束旋转仅限于重力方向，因此位姿仅4个自由度。")]),t._v(" "),e("p",[t._v("2.其次只关注部分room-scale物体（例如椅子，沙发，汽车），不考虑物体的对称性，本文关注hand-scale的物体（例如杯子，瓶子）。")]),t._v(" "),e("p",[t._v("3.本文还可以在不假设重力方向的情况下预测完整的6D位姿和大小")]),t._v(" "),e("p",[t._v("4.速度更快")]),t._v(" "),e("h2",{attrs:{id:"什么是nocs"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#什么是nocs"}},[t._v("#")]),t._v(" 什么是NOCS")]),t._v(" "),e("p",[t._v("NOCS(Normalized Object Coordinate Space)是一个包含在单位立方体中的三维空间，对于给定的物体类别，使用规范化朝向的实例，并将其归一化到NOCS中。NOCS中每个点(x,y,z)都能可视化为RGB颜色元组。我们训练网络将NOCS投影到RGB图像上，即NOCS map（下图左下角）。在测试时，网络对NOCS图进行回归，然后与深度图一起用于6D位姿和尺寸的估计。")]),t._v(" "),e("p",[t._v("本文关注图像的3+3+3（旋转，位姿，尺寸），能够可视化为下图中的c")]),t._v(" "),e("p",[e("img",{attrs:{src:a(400),alt:"2"}})]),t._v(" "),e("p",[t._v("给定每个类别的的CAD模型集合，我们对物体进行一致的缩放，**将"),e("strong",[e("strong",[t._v("tight bbox")])]),t._v("的对角线缩放到"),e("strong",[e("strong",[t._v("1")])]),t._v("，并且在"),e("strong",[e("strong",[t._v("NOCS")])]),t._v("中居中，**以此来归一化物体的尺寸。")]),t._v(" "),e("p",[t._v("然后，对其同一类物体的中心和朝向，使用ShapeNetCore中的物体模型针对比例、位置和方向进行规范化。如下图为相机中一个物体的规范化示例")]),t._v(" "),e("p",[e("img",{attrs:{src:a(401),alt:"image-20220314191449603"}})]),t._v(" "),e("p",[e("strong",[t._v("CNN"),e("strong",[e("strong",[t._v("预测彩色编码的")])]),t._v("NOCS"),e("strong",[e("strong",[t._v("坐标的")])]),t._v("2D****透视投影")]),t._v("，即NOCS map")]),t._v(" "),e("p",[t._v("有许多方式来解释NOCS图：")]),t._v(" "),e("p",[t._v("（1）作为物体观察到的部分在NOCS中的形状重建")]),t._v(" "),e("p",[t._v("（2）作为密集的 像素-NOCS对应")]),t._v(" "),e("p",[t._v("在大型形状集合上训练时，我们的CNN学习对未见过的物体形状进行泛化，或者说，学习预测像素-NOCS的对应关系")]),t._v(" "),e("p",[t._v("NOCS这种表示方式比其他方式（例如bbox）更加鲁棒，因为即便物体仅部分可见时仍然可以进行操作")]),t._v(" "),e("h2",{attrs:{id:"网络结构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#网络结构"}},[t._v("#")]),t._v(" 网络结构")]),t._v(" "),e("p",[t._v("使用RGB图和深度图作为输入，先看RGB")]),t._v(" "),e("p",[t._v("该CNN建立在Mask R-CNN框架的基础上，仅通过RGB图来估计类标签和instance mask以及NOCS map")]),t._v(" "),e("p",[t._v("在CNN中不使用深度图的原因是想要使用现有的RGB数据集（例如COCO这些没有深度信息的数据集）来提升性能。NOCS map 将物体的形状和size都encode到归一化空间，在稍后的阶段使用深度图（下图中的Depth）来提升这个归一化空间并使用鲁棒的异常值去除和对齐技术(如Umeyama算法)来预测完整的6D位姿和size")]),t._v(" "),e("p",[e("img",{attrs:{src:a(402),alt:"3"}})]),t._v(" "),e("h2",{attrs:{id:"数据集相关"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据集相关"}},[t._v("#")]),t._v(" 数据集相关")]),t._v(" "),e("p",[t._v("关于NOCS数据集的类标签，代码和数据集中是用下标来表示的。例如0代表bottle类。")]),t._v(" "),e("p",[t._v("['bottle', 'bowl', 'camera', 'can', 'laptop', 'mug']")]),t._v(" "),e("p",[t._v("下载链接")]),t._v(" "),e("p",[t._v("This links are all from captra")]),t._v(" "),e("p",[t._v("# current path relative to project root (captra): data/nocs_data/nocs_full")]),t._v(" "),e("p",[t._v("wget http://download.cs.stanford.edu/orion/nocs/camera_train.zip")]),t._v(" "),e("p",[t._v("unzip camera_train.zip")]),t._v(" "),e("p",[t._v("wget http://download.cs.stanford.edu/orion/nocs/camera_val25K.zip")]),t._v(" "),e("p",[t._v("unzip camera_val25K.zip")]),t._v(" "),e("p",[t._v("wget http://download.cs.stanford.edu/orion/nocs/real_train.zip")]),t._v(" "),e("p",[t._v("unzip real_train.zip")]),t._v(" "),e("p",[t._v("# evaluation")]),t._v(" "),e("p",[t._v("wget http://download.cs.stanford.edu/orion/nocs/real_test.zip")]),t._v(" "),e("p",[t._v("unzip real_test.zip")]),t._v(" "),e("p",[t._v("# obj_model")]),t._v(" "),e("p",[t._v("wget http://download.cs.stanford.edu/orion/nocs/obj_models.zip")]),t._v(" "),e("p",[t._v("unzip obj_models.zip")]),t._v(" "),e("p",[t._v("# Other")]),t._v(" "),e("p",[t._v("# Download and unzip nocs_model_corners.tar")]),t._v(" "),e("p",[t._v("# where the 3D bounding boxes of normalized object models are saved")]),t._v(" "),e("p",[t._v("wget http://download.cs.stanford.edu/orion/captra/nocs_model_corners.tar")]),t._v(" "),e("p",[t._v("tar -xzvf nocs_real_corners.tar")]),t._v(" "),e("p",[t._v("数据集的结构放到其他文章和代码一块提吧")])])}),[],!1,null,null,null);_.default=v.exports}}]);