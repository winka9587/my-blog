(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{516:function(t,n,a){t.exports=a.p+"assets/img/20200518213156800.da53db53.jpg"},517:function(t,n,a){t.exports=a.p+"assets/img/20200518213225411.b4fbf4cd.jpg"},518:function(t,n,a){t.exports=a.p+"assets/img/20200528172851936.c408e24e.jpg"},519:function(t,n,a){t.exports=a.p+"assets/img/20200528173105223.f2ab787c.jpg"},520:function(t,n,a){t.exports=a.p+"assets/img/20200528174818822.af6de7c6.jpg"},521:function(t,n){t.exports="data:image/jpeg;base64,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"},522:function(t,n,a){t.exports=a.p+"assets/img/20200528180731985.5f6572f5.jpg"},523:function(t,n,a){t.exports=a.p+"assets/img/20200601114306564.cced3a65.png"},524:function(t,n,a){t.exports=a.p+"assets/img/20200601103300364.b7b9fff4.jpg"},525:function(t,n,a){t.exports=a.p+"assets/img/20200602115016222.97e576e0.png"},526:function(t,n,a){t.exports=a.p+"assets/img/20200601112341968.2cbdf21c.jpg"},527:function(t,n,a){t.exports=a.p+"assets/img/2020060111383357.51a801c0.jpg"},586:function(t,n,a){"use strict";a.r(n);var e=a(56),s=Object(e.a)({},(function(){var t=this,n=t.$createElement,e=t._self._c||n;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"基于svm的划线框识别-1-hog特征提取"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基于svm的划线框识别-1-hog特征提取"}},[t._v("#")]),t._v(" 基于SVM的划线框识别（1）HOG特征提取")]),t._v(" "),e("p",[t._v("虽然上过机器学习的课程，但是那么课既没有课程设计也没有需要敲代码的作业，寻思着毕业设计选一个来挑战一下。“划线框识别”这个题目有两个，一个是深度学习实现，另一个是支持向量机实现，和舍友一人选了一个。考研复试结束了没什么事情，开始动手写这个，指不定自己哪天就忘了。")]),t._v(" "),e("p",[t._v("还是写博客舒服，写论文太痛苦。")]),t._v(" "),e("h2",{attrs:{id:"工具"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#工具"}},[t._v("#")]),t._v(" 工具")]),t._v(" "),e("p",[e("strong",[t._v("python + libsvm + opencv")])]),t._v(" "),e("p",[e("strong",[t._v("SVM选择的是C_SVC和RBF内核")])]),t._v(" "),e("h2",{attrs:{id:"背景"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#背景"}},[t._v("#")]),t._v(" 背景")]),t._v(" "),e("p",[t._v("刚刚看到题目的时候我以为“划线框”和答题卡差不多，后来看了一下数据集确实没有见过，可能一些调查问卷会用这种？调查问卷也只接触过打 √ 打勾的，倒是不需要用2B铅笔来涂。")]),t._v(" "),e("p",[t._v("目标就是用这些数据训练一个SVM模型来实现对这种划线框的识别。")]),t._v(" "),e("p",[t._v("划线框的图片示例（一部分）：")]),t._v(" "),e("p",[e("img",{attrs:{src:a(516),alt:"img"}}),t._v(" 有效样本")]),t._v(" "),e("p",[e("img",{attrs:{src:a(517),alt:"img"}}),t._v(" 无效样本")]),t._v(" "),e("h2",{attrs:{id:"hog特征提取"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hog特征提取"}},[t._v("#")]),t._v(" HOG特征提取")]),t._v(" "),e("p",[t._v("选择的特征是HOG特征，后期的时候准确率上不去，想到既然样本里笔迹都是红色的，那么是不是也可以用一下颜色，加了颜色直方图特征，结果相比于原来只用HOG，效果并没有什么变化。")]),t._v(" "),e("p",[t._v("学习的时候参考的是：")]),t._v(" "),e("p",[t._v("python opencv教程里面****"),e("a",{attrs:{href:"https://docs.opencv.org/3.4/dd/d3b/tutorial_py_svm_opencv.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("使用SVM进行手写图片识别"),e("OutboundLink")],1),t._v("*"),e("em",[e("strong",[t._v("以及")])]),t._v("*"),e("a",{attrs:{href:"https://www.learnopencv.com/histogram-of-oriented-gradients/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Histogram of Oriented Gradients"),e("OutboundLink")],1),t._v("****，其实搜一下HOG能发现很多博客都翻译过这篇文章。比较着这两篇里面的讲述和代码，差不多能够理解HOG特征提取的流程。在按照这两篇文章学习时的一些问题：")]),t._v(" "),e("p",[t._v("1、我通过Sobel算子在水平方向和竖直方向卷积之后得到的图像如下。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(518),alt:"img"}}),t._v(" 1：原图像，2：Gx，3：Gy，4：梯度图像")]),t._v(" "),e("p",[t._v("而Histogram of Oriented Gradients中使用算子卷积之后的图像是像下面这样的。（分别对应上图的2-4）")]),t._v(" "),e("p",[e("img",{attrs:{src:a(519),alt:"img"}}),e("img",{attrs:{src:"data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==",alt:"点击并拖拽以移动"}})]),t._v(" "),e("p",[t._v("出现这样的情况是因为我计算完梯度之后再显示图片时，每个像素点处值的范围是0~255，只需将其映射到0~1即可。")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("img = np.float32(img)/255.0\n")])])]),e("p",[e("img",{attrs:{src:a(520),alt:"img"}}),e("img",{attrs:{src:"data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==",alt:"点击并拖拽以移动"}})]),t._v(" "),e("p",[t._v("越亮的地方值越大，说明梯度变化也越大。")]),t._v(" "),e("p",[t._v("2、因为最后的block是为了归一化，来减小光照的影响，我看了一下手里的样本，光照的影响几乎没有，于是就将最后block那一步给省略掉了。")]),t._v(" "),e("h2",{attrs:{id:"hog特征提取实现代码"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hog特征提取实现代码"}},[t._v("#")]),t._v(" HOG特征提取实现代码")]),t._v(" "),e("p",[t._v("计算HOG特征的代码放在末尾，拆开说说其中的几个部分。")]),t._v(" "),e("p",[t._v("1、提取特征之前的预处理。一开始我只是单纯地使用一个阈值进行划分，将图像转换为二值图像，但是在后期训练的时候我发现这样的处理有问题。像是下面这个图像，仅使用单个阈值进行二值化，选项“11”本身在二值化后是被保留的。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(521),alt:"img"}})]),t._v(" "),e("p",[t._v("但我们其实并不关心黑色选项，我们只关心红色的笔迹。而且因为有的选项是个位数，有的选项是两位数，有的甚至带着小数点，就会导致选项对提取出的特征有很大的影响，所以需要排除选项对特征提取的干扰。")]),t._v(" "),e("p",[t._v("后期正确率一直上不去。我一开始以为是特征维度不够，试着将HOG划分的更细，也试着增加了颜色直方图特征。对准确率的提升效果都不大。后来使用了双阈值划分，即设置两个阈值min和max，如果像素点的值在min和max之间，那么值被保留，否则被置为0。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(522),alt:"img"}}),t._v(" 1.原图像  2.双阈值划分后 3.腐蚀后 4.按位取反后")]),t._v(" "),e("p",[t._v("腐蚀是因为只靠双阈值划分还是会有选项的一些边缘残留，因为我的样本图像本身尺寸就很小，只能使用最小的2x2大小的腐蚀算子，用3x3的就差不多已经渣都不剩了。")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("#输入图像路径，将图像通过两个阈值分割\n#阈值分割后的图像按2*2的邻域大小的模板进行腐蚀，只留下划线框\ndef HandleImgByThreshAndErode(img_gray):\n    #读取灰度图像\n    #img_gray = cv.imread(path, cv.IMREAD_GRAYSCALE)\n\n    #两个阈值处理\n    # THRESH_TOZERO将小于阈值的灰度值设为0，大于阈值的值保持不变\n    retvl, img_gray = cv.threshold(img_gray, svm_parameter.bottom_thresh, 255, cv.THRESH_TOZERO)\n    # THRESH_TOZERO_INV 将大于阈值的灰度值设为0，小于阈值的值保持不变\n    retvl, img_gray = cv.threshold(img_gray, svm_parameter.top_thresh, 255, cv.THRESH_TOZERO_INV)\n\n    #生成2*2的核 再大会腐蚀过头\n    kernel = np.ones((2, 2), np.uint8)\n    #腐蚀灰度图像 迭代一次就够了\n    img_final = cv.erode(img_gray, kernel, iterations=1)\n    #按位取反\n    img_final = cv.bitwise_not(img_final)\n    #得到的结果还是一个灰度图，可以拿去计算HOG特征\n\n    return img_final\n")])])]),e("p",[t._v("有了gx和gy之后就可以计算梯度向量，举一个简单情况方便理解。")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("    gx = cv.Sobel(img, cv.CV_32F, 1, 0)\n    gy = cv.Sobel(img, cv.CV_32F, 0, 1)\n    #计算梯度和梯度变化方向\n    mag, ang = cv.cartToPolar(gx, gy)\n")])])]),e("p",[e("img",{attrs:{src:a(523),alt:"img"}}),e("img",{attrs:{src:"data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==",alt:"点击并拖拽以移动"}})]),t._v(" "),e("p",[t._v("在直方图相关的概念中，"),e("strong",[t._v("bin")]),t._v("经常出现，其实bin指的就是直方图中出现的“柱”。比如下图中就有7个bin，“bin=1”可以理解为“柱1”，其存储的值为a。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(524),alt:"img"}}),e("img",{attrs:{src:"data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==",alt:"点击并拖拽以移动"}})]),t._v(" "),e("p",[t._v("output = np.bincount(a)，a是1维数组，其元素为非负整数。计数数组a中每个元素出现的次数，然后以元素为下标，值为出现次数输出结果。")]),t._v(" "),e("p",[t._v("a = [1,0,0,0,5,3,0,0,1]，其中0出现了5次，1出现了2次，3和5都出现了1次,2和4出现了0次。"),e("strong",[t._v("m出现了n次，output [m]=n")]),t._v("。")]),t._v(" "),e("p",[t._v("output = [5,2,0,1,0,1]")]),t._v(" "),e("p",[t._v("output = np.bincount(a,weight),当有第二个参数[数组]时，计算的就不再是每个元素出现的次数，而是以b中的元素作为a中对应下标元素的权重，计算a中同一元素的权重之和。")]),t._v(" "),e("p",[t._v("a = [1,0,0,0,5,3,0,0,1]")]),t._v(" "),e("p",[t._v("w = [5,1,3,4,2,1,2,2,3]")]),t._v(" "),e("p",[t._v("a中元素1出现在下标0的位置，那么output[1]+=w[0]，1还出现在下标8，output[1]+=w[8]。")]),t._v(" "),e("p",[t._v("output = [12,8,0,1,0,2]")]),t._v(" "),e("p",[t._v("也就是说当只有一个参数时，权重默认都是1。")]),t._v(" "),e("p",[t._v("关于bincount这个函数，****"),e("a",{attrs:{href:"https://blog.csdn.net/xlinsist/article/details/51346523",target:"_blank",rel:"noopener noreferrer"}},[t._v("这个老哥"),e("OutboundLink")],1),t._v("****讲得比较清楚，当然最好还是自己动手试一试。")]),t._v(" "),e("p",[t._v("在python-opencv教程的代码中比较难理解的是这一行。")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("hists = [np.bincount(b.ravel(), m.ravel(), bin_n)  for b, m in zip(bin_cells, mag_cells)]\n")])])]),e("p",[t._v("zip函数将bin_cells和mag_cells中的元素一对一对地打包成元组，例如a=[元素a1,元素a2,元素a3]，b=[元素b1,元素b2,元素b3]，那么zip(a,b)=[(元素a1,元素b1),(元素a2,元素b2),(元素a3,元素b3)]。然后使用for循环提取出其中的每一对，用b,m存储，以便在bincount函数中使用。")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("bin_cells = bins[:center_row,:center_col], \n            bins[center_row:,:center_col], \n            bins[:center_row,center_col:], \n            bins[center_row:,center_col:]\nmag_cells = mag[:center_row,:center_col], \n            mag[center_row:,:center_col], \n            mag[:center_row,center_col:], \n            mag[center_row:,center_col:]\n")])])]),e("p",[t._v("可以在上面看到，bin_cells和mag_cells都只有4个元素且都是矩阵。那么for循环中的每一对b,m也是一对矩阵。")]),t._v(" "),e("p",[t._v("使用ravel函数是将二维的b和m扁平化，方便进行遍历，原本n"),e("em",[t._v("m的数据变成(n")]),t._v("m)的一维数据。bins中记录的是梯度变化的方向，mag中记录的是梯度值。以方向作为bin，以梯度值为权重，计算bincount。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(525),alt:"img"}}),e("img",{attrs:{src:"data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==",alt:"点击并拖拽以移动"}})]),t._v(" "),e("p",[t._v("最终hists是一个包含4个元素的数组，这4个元素都是1维数组，每个都至少有16项。因为是都是一维数组，使用hstack相当于将他们拼接成一个数组。")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("hist = np.hstack(hists)\n")])])]),e("p",[t._v("之所以要使用hstack而不是vstack，因为这4个cell每个都作为独立的一部分，使用vstack就相当于将整个图像作为一个cell，前面做的划分等工作也就没意义了。就好比你将语数英综合4门成绩列出来能看出来一个学生擅长什么不擅长什么，而只列出一个总分就只能看到他的总体水平。划分为4个cell是因为样本图像本身大小并不大。划分太小像素点都有些不够用...具体使用多少cell要根据自己的实际情况来决定。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(526),alt:"img"}})]),t._v(" "),e("p",[e("strong",[t._v("完整代码：")])]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v('def GetHOGFeature(img_src,show_img=False,show_gradient_img=False,show_gradient_img_isGray=False):\n    #彩色图像，之后可能会用来显示与原图像的对比\n    #img_3c = img_src.copy()\n    #灰度图像\n    img_1c = cv.cvtColor(img_3c,cv.COLOR_BGR2GRAY)\n    #这里是自己写的一个“双阈值化+腐蚀”的函数，主要是对图像进行预处理\n    img_1c = HandleImgByThreshAndErode(img_1c)\n\n    img = img_1c.copy()\n    #GetBinary是获得一个二值化函数\n    img = GetBinaryImg(img)\n\n    #bin_n为梯度直方图至少有多少列\n    bin_n = 16\n    #分别在水平和竖直方向使用Sobel进行卷积\n    gx = cv.Sobel(img, cv.CV_32F, 1, 0)\n    gy = cv.Sobel(img, cv.CV_32F, 0, 1)\n    #计算梯度和梯度变化方向\n    mag, ang = cv.cartToPolar(gx, gy)\n    #ang为Mat类型\n    #量化\n    #cartToPolar默认输出的ang是弧度0到2π\n    #有符号梯度 将角度的值从[0,2π]映射到[0,16]\n    #bins = np.int32(bin_n*ang/(2*np.pi))\n    #无符号梯度，将角度的值从[0,2π]映射到[0,16]，但是将a和a+pi看做是一样的\n    bins = np.int32(bin_n*(ang%np.pi)/(np.pi))\n    # 每个bins中对应的坐标x都从0到np.size(bins,1)  y从0到np.size(bins,0)\n\n    # bins(mag)、ang图像划分为4个子矩形\n    # bin_cells和mag_cell的类型应为Mat数组\n    center_row = int(img.shape[0]/2)\n    center_col = int(img.shape[1]/2)\n    \n    bin_cells = bins[:center_row,:center_col], bins[center_row:,:center_col], bins[:center_row,center_col:], bins[center_row:,center_col:]\n    mag_cells = mag[:center_row,:center_col], mag[center_row:,:center_col], mag[:center_row,center_col:], mag[center_row:,center_col:]\n    hists = [np.bincount(b.ravel(), m.ravel(), bin_n)  for b, m in zip(bin_cells, mag_cells)]\n\n    hist = np.hstack(hists)\n    #print("HOG特征元素个数")\n    #print(len(hist))\n\n    #保留2位小数方便计算\n    hist = np.round(hist,2)\n\n    return hist\n')])])]),e("h2",{attrs:{id:"可视化"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#可视化"}},[t._v("#")]),t._v(" 可视化")]),t._v(" "),e("p",[t._v("试着根据计算出来的梯度向量在原图像上绘制了一下。能让效果直观一点。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(527),alt:"img"}}),e("img",{attrs:{src:"data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==",alt:"点击并拖拽以移动"}})])])}),[],!1,null,null,null);n.default=s.exports}}]);